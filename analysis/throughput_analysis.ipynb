{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries to visualize the analysis of the csv file generated.\n",
    "Seaborn is used to magnify the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Use Seaborn's context settings to make fonts larger.\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv file and print the data frame of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/home/piyush/Desktop/Study/Research Project/ClusterScheduler/gavel/analysis/output.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform queries on the data frame generated from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how does the batch size of a model change the throughput with respect to a fixed worker type and model. Only one model per GPU. Also how does the scale (no. of GPU's impact this.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker_name in df[\"worker\"].unique():\n",
    "    for model in df[\"model1\"].unique():    \n",
    "        result_int = df.query(f'model2 == \"x\" & model1 == \"{model}\" & worker == \"{worker_name}\"')\n",
    "\n",
    "        no_graphs = len(result_int[\"scale1\"].unique())\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "        bar_width = 0.2\n",
    "\n",
    "        for idx, scale in enumerate(result_int[\"scale1\"].unique()):\n",
    "            result = result_int.query(f'scale1 == {scale}')\n",
    "            x = np.arange(len(result[\"batchsize1\"].unique()))\n",
    "            b = ax.bar(x + (bar_width * idx), result[\"throughput1\"], width=bar_width, label=f'Scale:{scale}')\n",
    "            \n",
    "            ax.set_xticks(x + (no_graphs - 1) * (bar_width / 2))\n",
    "            ax.set_xticklabels(result[\"batchsize1\"].unique())\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_color('#DDDDDD')\n",
    "        ax.tick_params(bottom=False, left=False)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.yaxis.grid(True, color='#EEEEEE')\n",
    "        ax.xaxis.grid(False)\n",
    "\n",
    "        ax.set_xlabel('Batch Size', labelpad=15)\n",
    "        ax.set_ylabel('Throughput', labelpad=15)\n",
    "        ax.set_title(f'Worker : {worker_name}, Model : {model}', pad=15)\n",
    "\n",
    "        # For each bar in the chart, add a text label.\n",
    "        for bar in ax.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "            bar_value = bar.get_height()\n",
    "            # Format the text with commas to separate thousands. You can do\n",
    "            # any type of formatting here though.\n",
    "            text = f'{bar_value:,}'\n",
    "            # This will give the middle of each bar on the x-axis.\n",
    "            text_x = bar.get_x() + bar.get_width() / 2\n",
    "            # get_y() is where the bar starts so we add the height to it.\n",
    "            text_y = bar.get_y() + bar_value\n",
    "            # If we want the text to be the same color as the bar, we can\n",
    "            # get the color like so:\n",
    "            bar_color = bar.get_facecolor()\n",
    "            # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "            ax.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                    size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the throughput of different isolated models on a single accelerator type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker_name in df[\"worker\"].unique():\n",
    "    res1 = df.query(f'worker == \"{worker_name}\" & model2 == \"x\"')\n",
    "    for scale in res1[\"scale1\"].unique():\n",
    "        res2 = res1.query(f'scale1 == {scale}')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "        bar_width = 0.4\n",
    "\n",
    "        no_graphs = len(res2[\"model1\"].unique())\n",
    "\n",
    "        res_arr = []\n",
    "        name_arr = []\n",
    "\n",
    "        for idx, model in enumerate(res2[\"model1\"].unique()):\n",
    "            res3 = res2.query(f'model1 == \"{model}\"')\n",
    "\n",
    "            res4 = res3.loc[ lambda res3 : res3[\"throughput1\"].idxmax(), : ]\n",
    "\n",
    "            # res_arr.append(res3[\"throughput1\"].max())\n",
    "            # name_arr.append(model)\n",
    "            res_arr.append(res4[\"throughput1\"])\n",
    "            name_arr.append(f'{res4[\"model1\"]}({res4[\"batchsize1\"]})')\n",
    "\n",
    "        ax.bar(name_arr, res_arr, width=bar_width)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_color('#DDDDDD')\n",
    "        ax.tick_params(bottom=False, left=False)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.yaxis.grid(True, color='#EEEEEE')\n",
    "        ax.xaxis.grid(False)\n",
    "\n",
    "        ax.set_xlabel('Model(Batch Size)', labelpad=15)\n",
    "        ax.set_ylabel('Throughput', labelpad=15)\n",
    "        ax.set_title(f'Worker : {worker_name}, Scale : {scale}', pad=15)\n",
    "\n",
    "        # For each bar in the chart, add a text label.\n",
    "        for bar in ax.patches:\n",
    "        # The text annotation for each bar should be its height.\n",
    "            bar_value = bar.get_height()\n",
    "            # Format the text with commas to separate thousands. You can do\n",
    "            # any type of formatting here though.\n",
    "            text = f'{bar_value:,}'\n",
    "            # This will give the middle of each bar on the x-axis.\n",
    "            text_x = bar.get_x() + bar.get_width() / 2\n",
    "            # get_y() is where the bar starts so we add the height to it.\n",
    "            text_y = bar.get_y() + bar_value\n",
    "            # If we want the text to be the same color as the bar, we can\n",
    "            # get the color like so:\n",
    "            bar_color = bar.get_facecolor()\n",
    "            # If you want a consistent color, you can just set it as a constant, e.g. #222222\n",
    "            ax.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,\n",
    "                    size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "throughput of one model with other model in a worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     worker     model1  scale1  batchsize1  throughput1     model2  scale2  \\\n",
      "1       k80  ResNet-18       1          16     2.539980  ResNet-18       1   \n",
      "2       k80  ResNet-18       1          16     2.408173  ResNet-18       1   \n",
      "3       k80  ResNet-18       1          16     2.714823  ResNet-18       1   \n",
      "5       k80  ResNet-18       1          16     2.230568  ResNet-18       1   \n",
      "6       k80  ResNet-18       1          16     2.149960  ResNet-18       1   \n",
      "...     ...        ...     ...         ...          ...        ...     ...   \n",
      "1543    k80  ResNet-18       8         256     0.000000  ResNet-18       8   \n",
      "1544    k80  ResNet-18       8         256     0.000000  ResNet-18       8   \n",
      "1545    k80  ResNet-18       8         256     0.000000  ResNet-18       8   \n",
      "1546    k80  ResNet-18       8         256     0.000000  ResNet-18       8   \n",
      "1547    k80  ResNet-18       8         256     0.000000  ResNet-18       8   \n",
      "\n",
      "      batchsize2  throughput2  \n",
      "1             32     3.120193  \n",
      "2             16     2.408173  \n",
      "3             64     3.107321  \n",
      "5            128     0.955970  \n",
      "6            256     0.488166  \n",
      "...          ...          ...  \n",
      "1543          16     0.000000  \n",
      "1544          32     0.000000  \n",
      "1545          64     0.000000  \n",
      "1546         128     0.000000  \n",
      "1547         256     0.000000  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# for worker_name in df[\"worker\"]:\n",
    "#     res = df.query(f'worker == \"{worker_name}\" & model2 != \"x\" & scale1 == scale2')\n",
    "#     for model in res[\"model1\"].unique():\n",
    "#         res1 = res.query(f'model1 == \"{model}\"')\n",
    "#         res2 = res1.query('model1 == model2')\n",
    "#         print(res2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2dc0f497f1bbcf561861539b4d85ea055ed3a41f2781b30e7afbcc38ab08fc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
